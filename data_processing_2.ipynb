{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64    26\n",
      "object      5\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Signif_Avg', 'Pivot_Energy', 'Flux1000', 'Energy_Flux100',\n",
       "       'PL_Flux_Density', 'PL_Index', 'LP_Flux_Density', 'LP_Index', 'LP_beta',\n",
       "       'LP_SigCurv', 'LP_EPeak', 'PLEC_Flux_Density', 'PLEC_IndexS',\n",
       "       'PLEC_ExpfactorS', 'PLEC_Exp_Index', 'PLEC_SigCurv', 'PLEC_EPeak',\n",
       "       'Npred', 'Flux_Band', 'nuFnu_Band', 'Sqrt_TS_Band', 'Variability_Index',\n",
       "       'Frac_Variability', 'Signif_Peak', 'Flux_Peak', 'Time_Peak',\n",
       "       'Peak_Interval', 'Flux_History', 'Sqrt_TS_History', 'ASSOC_PROB_BAY',\n",
       "       'ASSOC_PROB_LR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from astropy.io import ascii\n",
    "\n",
    "table = ascii.read('hdu1.txt')\n",
    "fermi_lat = table.to_pandas()\n",
    "fermi_lat.to_csv('hdu1.csv')\n",
    "fl = fermi_lat.drop(columns=['ROI_num','RA_Counterpart','DEC_Counterpart','Conf_68_SemiMajor', 'Conf_68_SemiMinor', 'Conf_68_PosAng',\n",
    "       'Conf_95_SemiMajor', 'Conf_95_SemiMinor', 'Conf_95_PosAng','RAJ2000', 'DEJ2000','DataRelease','GLON','GLAT','Source_Name',\n",
    "       'Extended_Source_Name','SpectrumType','ASSOC_4FGL','ASSOC_FGL','ASSOC_FHL','ASSOC_GAM1','ASSOC_GAM2','ASSOC_GAM3','TEVCAT_FLAG',\n",
    "       'ASSOC_TEV','CLASS1','CLASS2','ASSOC1','ASSOC2','Flags'])\n",
    "\n",
    "uncertainties = np.array([])\n",
    "for x in fl.columns:\n",
    "    if 'Unc' in x:\n",
    "        uncertainties = np.append(uncertainties,x)\n",
    "fl = fl.drop(columns=uncertainties)\n",
    "print(fl.dtypes.value_counts())\n",
    "fl.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col0 = np.zeros(len(fl))\n",
    "col1 = np.zeros(len(fl))\n",
    "col2 = np.zeros(len(fl))\n",
    "col3 = np.zeros(len(fl))\n",
    "col4 = np.zeros(len(fl))\n",
    "col5 = np.zeros(len(fl))\n",
    "col6 = np.zeros(len(fl))\n",
    "col7 = np.zeros(len(fl))\n",
    "\n",
    "columnlist = ['Flux_Band', 'Unc_Flux_Band', 'nuFnu_Band', 'Sqrt_TS_Band',\n",
    "       'Flux_History', 'Unc_Flux_History', 'Sqrt_TS_History']\n",
    "\n",
    "for name in columnlist:    \n",
    "    for i in range(0,len(fl)):\n",
    "        obj_data = fl[name][i]\n",
    "        obj_data = obj_data.replace('[','') \n",
    "        obj_data = obj_data.replace(']','') \n",
    "        obj_data = obj_data.replace('null','0')\n",
    "        float_data = [float(idx) for idx in obj_data.split(',')]\n",
    "        for x in range(0,len(float_data)):\n",
    "            if float_data[x] == 0:\n",
    "                float_data[x] = np.nan\n",
    "        col0[i] = float_data[0]\n",
    "        col1[i] = float_data[1]\n",
    "        col2[i] = float_data[2]\n",
    "        col3[i] = float_data[3]\n",
    "        col4[i] = float_data[4]\n",
    "        col5[i] = float_data[5]\n",
    "        col6[i] = float_data[6]\n",
    "        col7[i] = float_data[7]\n",
    "    fl[name + '_0'] = col0\n",
    "    fl[name+'_1'] = col1\n",
    "    fl[name+'_2'] = col2\n",
    "    fl[name+'_3'] = col3\n",
    "    fl[name+'_4'] = col4\n",
    "    fl[name+'_5'] = col5\n",
    "    fl[name+'_6'] = col6\n",
    "    fl[name+'_7'] = col7\n",
    "\n",
    "fl = fl.drop(columns=columnlist)\n",
    "\n",
    "fl.to_csv('ML_input.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glossary of Terms and Acronyms:\n",
    "\n",
    "PLEC = Power Law Exponential Cutoff\n",
    "TS = Test Statistic: Used as threshold for inclusion of new sources.\n",
    "ROI = Region of Interest??\n",
    "Unc = Uncertainty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IoanPJ/Final_year_project_IMPJ/blob/main/ML/imbalanced_CL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "C3xcXEpyNE2W"
      },
      "outputs": [],
      "source": [
        "import imblearn\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, log_loss, roc_auc_score, RocCurveDisplay, roc_curve\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#from IMPJ import DataProcessor\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from os.path import basename, exists\n",
        "import matplotlib as mpl\n",
        "import random\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from tqdm import tqdm\n",
        "\n",
        "#dp = DataProcessor()\n",
        "\n",
        "def download(url):\n",
        "    filename = basename(url)\n",
        "    if not exists(filename):\n",
        "        from urllib.request import urlretrieve\n",
        "        local, _ = urlretrieve(url, filename)\n",
        "        print('Downloaded ' + local)\n",
        "\n",
        "download('https://github.com/AllenDowney/AstronomicalData/raw/main/' + 'az-paper-twocol.mplstyle')\n",
        "plt.style.use('./az-paper-twocol.mplstyle')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ly_EmtuuNKkq",
        "outputId": "e693a986-1495-4e95-e48a-7fb9931a53a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "s88SZaA3NE2a"
      },
      "outputs": [],
      "source": [
        "test_size = 0.3\n",
        "\n",
        "filepath = \"/content/drive/My Drive/Colab Notebooks/chiaro_12.csv\"\n",
        "data = pd.read_csv(filepath, index_col=0)\n",
        "data = data.dropna()\n",
        "Y = np.array(data['CLASS1'])\n",
        "X = np.array(data.drop(labels='CLASS1',axis=1))\n",
        "#X,Y = dp.choose_2_vars('CLASS1',data,1,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "liRn_Ys_NE2c"
      },
      "outputs": [],
      "source": [
        "Y[Y==2]=1 # non radio galaxies\n",
        "Y[Y==3]=0 # radio galaxies\n",
        "\n",
        "init_ratio = len(Y[Y==0])/len(Y[Y==1])\n",
        "\n",
        "sm = SMOTE(random_state=42, sampling_strategy=init_ratio*5)\n",
        "ru = RandomUnderSampler(random_state=42, sampling_strategy=1)\n",
        "\n",
        "scaler = StandardScaler()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "k0a2IqueNE2d",
        "outputId": "b8f611fc-6b89-4fcc-91bb-4140593a6013",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10it [09:21, 56.11s/it]\n"
          ]
        }
      ],
      "source": [
        "NN = MLPClassifier(activation='tanh',hidden_layer_sizes=(50,50),learning_rate='constant',solver='sgd',\n",
        "                   max_iter=5000,random_state=5)\n",
        "BNN = BaggingClassifier(estimator=NN,n_estimators=5,bootstrap=True,verbose=0,n_jobs=-1)\n",
        "#ovr = OneVsRestClassifier(estimator=BNN, n_jobs=-1,verbose=10)\n",
        "iteration=0\n",
        "kf = KFold(n_splits=10)\n",
        "\n",
        "y_pred=pd.DataFrame()\n",
        "y_proba=pd.DataFrame()\n",
        "y_test_df=pd.DataFrame()\n",
        "\n",
        "\n",
        "for train_indices, test_indices in tqdm(kf.split(X)):\n",
        "    iteration+=1\n",
        "    x_train=X[train_indices]\n",
        "    y_train = Y[train_indices]\n",
        "    x_test=X[test_indices]\n",
        "    y_test=Y[test_indices]\n",
        "    y_test_df['iteration '+str(iteration)] = y_test\n",
        "    scaler.fit(x_train)\n",
        "    x_train = scaler.transform(x_train)\n",
        "    x_test = scaler.transform(x_test)\n",
        "    #print(f'Initial Ratio: {len(y_train[y_train==0])/len(y_train[y_train==1])}')\n",
        "    #print(f'Original Dataset Shape: {Counter(y_train)}')\n",
        "    x_train_sm, y_train_sm = sm.fit_resample(x_train, y_train)\n",
        "    x_train_res, y_train_res = ru.fit_resample(x_train_sm,y_train_sm)\n",
        "    #print(f'New Ratio: {len(y_train_res[y_train_res==0])/len(y_train_res[y_train_res==1])}')\n",
        "    #print(f'Resampled dataset shape {Counter(y_train_res)}')\n",
        "    BNN.fit(x_train_res, y_train_res)\n",
        "\n",
        "    y_pred['iteration '+str(iteration)] = BNN.predict(x_test)\n",
        "    y_proba['class' + str(0) + ' iteration '+ str(iteration)] = BNN.predict_proba(x_test).T[0]\n",
        "    y_proba['class'+str(1)+' iteration '+str(iteration)]= BNN.predict_proba(x_test).T[1]\n",
        "#BNN.fit(x_train_res,y_train_res)\n",
        "y_pred.to_csv(\"/content/drive/My Drive/Colab Notebooks/imbalanced_trials/y_pred.csv\")\n",
        "y_proba.to_csv(\"/content/drive/My Drive/Colab Notebooks/imbalanced_trials/y_proba.csv\")\n",
        "y_test_df.to_csv(\"/content/drive/My Drive/Colab Notebooks/imbalanced_trials/y_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "JnNvqyKfNE2e",
        "outputId": "510cc8be-fda7-4317-89b0-f92f6978ffb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Classification metrics can't handle a mix of binary and multilabel-indicator targets",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-1339e5f66834>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m''' SCORING METRICS '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mconfusion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
          ]
        }
      ],
      "source": [
        "print(np.unique(y_train))\n",
        "\n",
        "''' SCORING METRICS '''\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)*100\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test,y_pred)\n",
        "roc_auc_weightedavg = roc_auc_score(y_test,y_pred,average='weighted')\n",
        "logloss = log_loss(y_test,y_pred)\n",
        "f1 = f1_score(y_test,y_pred)\n",
        "fpr, tpr, thresholds = roc_curve(y_test,y_proba.T[1])\n",
        "\n",
        "print('The Neural Network accuracy is ' + str(accuracy))\n",
        "print('The Neural Network ROC AUC Scores are: '+str(roc_auc))\n",
        "print(\"The Neural Network's Weighted Average ROC AUC Score is: \" + str(roc_auc_weightedavg))\n",
        "print(\"The Neural Network's Logarithmic Loss Score is: \" + str(logloss))\n",
        "print('The Neural Network F1 Score is: '+str(f1))\n",
        "print('The Neural Network Confusion Matrix is:')\n",
        "print(confusion)\n",
        "\n",
        "resultcols = ['Accuracy', 'ROC AUC', 'ROC Weighted Av', 'Logarithmic Loss',\n",
        "            'F1 Score', 'CMatrix11','CMatrix12', 'CMatrix21', 'CMatrix22']\n",
        "resultarray = np.array((accuracy,roc_auc,roc_auc_weightedavg,logloss,f1,\n",
        "                        confusion[0,0],confusion[0,1],confusion[1,0],confusion[1,1]))\n",
        "rocresultcols = ['FPR','TPR','Thresholds']\n",
        "rocresultarray = np.array([fpr,tpr,thresholds])\n",
        "#print(rocresultarray)\n",
        "results = pd.DataFrame([resultarray],columns=resultcols)\n",
        "rocresults = pd.DataFrame(np.array([fpr,tpr,thresholds]).transpose(),columns=rocresultcols)\n",
        "\n",
        "results.to_csv(\"/content/drive/My Drive/Colab Notebooks/imbalanced_trials/results1.csv\")\n",
        "rocresults.to_csv(\"/content/drive/My Drive/Colab Notebooks/imbalanced_trials/rocresults1.csv\")\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "\n",
        "ax.plot(fpr,tpr,linestyle='dashed',marker='x')\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DSIANtA2gqWQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
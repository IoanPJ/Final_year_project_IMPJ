{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, log_loss, roc_auc_score, RocCurveDisplay, roc_curve\n",
    "import wandb\n",
    "from wandb.sklearn import plot_precision_recall, plot_feature_importances\n",
    "from wandb.sklearn import plot_class_proportions, plot_learning_curve, plot_roc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IMPJ import DataProcessor\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import basename, exists\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "dp = DataProcessor()\n",
    "\n",
    "def download(url):\n",
    "    filename = basename(url)\n",
    "    if not exists(filename):\n",
    "        from urllib.request import urlretrieve\n",
    "        local, _ = urlretrieve(url, filename)\n",
    "        print('Downloaded ' + local)\n",
    "        \n",
    "download('https://github.com/AllenDowney/AstronomicalData/raw/main/' + 'az-paper-twocol.mplstyle')\n",
    "plt.style.use('./az-paper-twocol.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3\n",
    "    \n",
    "filepath = '..\\\\Fermi-LAT Data Subsets\\\\chiaro_12.csv'\n",
    "data = pd.read_csv(filepath, index_col=0)\n",
    "data = data.dropna()\n",
    "Y = data['CLASS1']\n",
    "X = data.drop(labels='CLASS1',axis=1)\n",
    "#X,Y = dp.choose_2_vars('CLASS1',data,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Shape: Counter({1: 1043, 2: 575, 3: 34})\n",
      "Resampled dataset shape Counter({1: 1043, 2: 1043, 3: 1043})\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=test_size,random_state=2) \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(x_train)  \n",
    "x_train = scaler.transform(x_train)  \n",
    "x_test = scaler.transform(x_test)  \n",
    "\n",
    "print(f'Original Dataset Shape: {Counter(y_train)}')\n",
    "x_train_res, y_train_res = sm.fit_resample(x_train, y_train)\n",
    "print(f'Resampled dataset shape {Counter(y_train_res)}')\n",
    "\n",
    "for i in range(0,len(y_test)):\n",
    "    if np.array(y_test)[i] == 3:\n",
    "        print(np.array(y_test)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = MLPClassifier(activation='tanh',hidden_layer_sizes=(50,50),learning_rate='constant',solver='sgd',\n",
    "                   max_iter=5000,random_state=5)\n",
    "BNN = BaggingClassifier(estimator=NN,n_estimators=20,bootstrap=True)\n",
    "ovr = OneVsRestClassifier(estimator=BNN, n_jobs=-1)\n",
    "ovr.fit(x_train_res,y_train_res)\n",
    "y_pred = ovr.predict(x_test)\n",
    "y_proba = ovr.predict_proba(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 2 1 1 2 1 2 1 2 1 3 2 1 2 1 1 1 1 2 1 1 1 1 3 1 1 1 1 1 1 1 2 1 1 2\n",
      " 2 1 1 1 3 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 2 1 1 1 2 1 1 2 2 1 2 1 1 1 1 2 1\n",
      " 1 1 1 1 2 2 1 2 1 2 2 2 1 3 1 1 1 1 1 1 1 2 2 1 1 2 2 2 2 1 2 1 2 1 1 1 1\n",
      " 1 1 2 2 2 1 2 1 1 1 2 1 1 2 1 2 1 2 2 1 1 1 2 3 1 1 2 1 2 1 2 1 1 1 1 2 1\n",
      " 1 2 1 1 1 1 2 1 2 1 1 2 2 1 1 2 2 2 1 1 3 1 1 3 2 1 1 1 1 1 1 1 3 3 2 2 2\n",
      " 1 1 3 3 2 2 3 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 2 3 1 1 1 1 1\n",
      " 1 1 2 2 1 1 2 1 2 2 2 1 3 1 1 2 2 3 1 1 1 2 2 1 2 1 3 2 1 1 1 1 1 1 2 1 1\n",
      " 2 2 1 1 2 1 1 2 2 1 1 1 1 2 1 1 1 1 2 1 1 2 1 1 1 2 1 1 1 1 1 2 1 1 3 1 2\n",
      " 1 1 2 1 3 1 1 1 2 1 1 2 1 1 1 2 2 3 1 3 1 3 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1\n",
      " 1 2 3 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 3 1 1 2 1 2 1 1 1 1 3 1 1 2 2 2 1 3 1\n",
      " 1 1 2 1 1 2 2 1 1 1 1 2 3 2 1 2 1 1 1 1 1 1 3 1 2 1 1 1 2 1 1 1 1 2 1 2 3\n",
      " 2 1 1 1 2 1 2 2 1 1 1 2 2 2 1 1 2 2 1 1 2 2 1 1 2 1 3 1 2 3 1 2 1 2 2 2 1\n",
      " 2 2 1 1 1 2 1 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 3 1 2 1 3 2 3 1 1 2 1 2 2 2 1\n",
      " 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 2 1 2 3 3 2 2 2 2 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 2 3 1 1 1 2 1 1 2 1 2 1 2 1 1 1 1 2 1 2 2 2 2 1 1 2 2 2 1 1 2 1 1 1\n",
      " 2 2 1 1 1 3 1 1 1 3 1 1 2 1 2 2 1 1 3 3 1 1 2 1 2 1 3 2 1 2 3 1 2 1 2 3 2\n",
      " 1 2 3 2 1 1 2 2 2 3 2 2 3 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 3 2 1 2 2 1\n",
      " 2 2 1 2 1 3 1 1 1 1 3 2 2 2 2 2 1 1 1 2 1 1 1 2 1 3 1 1 1 2 2 1 2 1 3 2 1\n",
      " 1 2 2 2 2 1 2 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 2 1 2 2 3 1 1 2 1 1 1 2 1 1 1\n",
      " 2 1 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "The Neural Network accuracy is 82.06214689265536\n",
      "[[372  31  44]\n",
      " [ 29 207   6]\n",
      " [ 13   4   2]]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train))\n",
    "\n",
    "''' SCORING METRICS '''\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)*100\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "#roc_auc = roc_auc_score(y_test,y_pred) \n",
    "#roc_auc_weightedavg = roc_auc_score(y_test,y_pred,average='weighted')\n",
    "#logloss = log_loss(y_test,y_pred)\n",
    "#f1 = f1_score(y_test,y_pred)\n",
    "#fpr, tpr, thresholds = roc_curve(y_test,y_proba.T[1])\n",
    "\n",
    "print('The Neural Network accuracy is ' + str(accuracy))\n",
    "#print('The Neural Network ROC AUC Scores are: '+str(roc_auc))\n",
    "#print(\"The Neural Network's Weighted Average ROC AUC Score is: \" + str(roc_auc_weightedavg))\n",
    "#print(\"The Neural Network's Logarithmic Loss Score is: \" + str(logloss))\n",
    "#print('The Neural Network F1 Score is: '+str(f1))\n",
    "#print('The Neural Network Confusion Matrix is:')\n",
    "print(confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

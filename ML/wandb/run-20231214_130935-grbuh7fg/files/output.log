The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
C:\Users\ioanp\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:458: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names
  warnings.warn(
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
C:\Users\ioanp\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:458: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names
  warnings.warn(
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
C:\Users\ioanp\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:458: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names
  warnings.warn(
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
C:\Users\ioanp\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:458: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names
  warnings.warn(
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
C:\Users\ioanp\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:458: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names
  warnings.warn(
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
C:\Users\ioanp\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:458: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names
  warnings.warn(
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
C:\Users\ioanp\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:458: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names
  warnings.warn(
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
C:\Users\ioanp\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:458: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names
  warnings.warn(
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
C:\Users\ioanp\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:458: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names
  warnings.warn(
C:\Users\ioanp\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:458: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names
  warnings.warn(
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
C:\Users\ioanp\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:458: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names
  warnings.warn(
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
C:\Users\ioanp\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:458: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names
  warnings.warn(
Downloaded az-paper-twocol.mplstyle
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
C:\Users\ioanp\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:458: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names
  warnings.warn(
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
C:\Users\ioanp\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:458: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names
  warnings.warn(
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
C:\Users\ioanp\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:458: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names
  warnings.warn(
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
C:\Users\ioanp\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:458: UserWarning: X has feature names, but BaggingClassifier was fitted without feature names
  warnings.warn(
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
The Neural Network F1 Score is: 0.8611111111111112
[[251  16]
 [ 24 124]]
[[6.17576509e-03 9.93824235e-01]
 [5.85528214e-01 4.14471786e-01]
 [9.93500354e-01 6.49964553e-03]
 [9.78386175e-01 2.16138250e-02]
 [9.96380175e-01 3.61982520e-03]
 [4.23693781e-01 5.76306219e-01]
 [9.98908556e-01 1.09144439e-03]
 [9.95420799e-01 4.57920111e-03]
 [9.84228305e-01 1.57716949e-02]
 [9.99211119e-01 7.88881402e-04]
 [9.62135815e-01 3.78641846e-02]
 [9.93271872e-01 6.72812831e-03]
 [9.91010357e-01 8.98964270e-03]
 [6.52521238e-02 9.34747876e-01]
 [9.92061170e-01 7.93882950e-03]
 [1.10319597e-03 9.98896804e-01]
 [3.12770890e-02 9.68722911e-01]
 [9.78364487e-01 2.16355125e-02]
 [1.02973525e-01 8.97026475e-01]
 [3.28832817e-03 9.96711672e-01]
 [2.65589680e-01 7.34410320e-01]
 [9.96658240e-01 3.34176012e-03]
 [9.99350572e-01 6.49428066e-04]
 [9.98358312e-01 1.64168761e-03]
 [9.96482109e-01 3.51789059e-03]
 [9.96950033e-01 3.04996739e-03]
 [9.94740372e-01 5.25962809e-03]
 [2.85947278e-04 9.99714053e-01]
 [9.96091377e-01 3.90862253e-03]
 [9.97820916e-01 2.17908447e-03]
 [9.99874468e-01 1.25531899e-04]
 [5.62397865e-03 9.94376021e-01]
 [7.48284546e-01 2.51715454e-01]
 [9.88766633e-01 1.12333669e-02]
 [8.29651203e-05 9.99917035e-01]
 [1.97873352e-03 9.98021266e-01]
 [1.91899952e-01 8.08100048e-01]
 [9.97051273e-01 2.94872702e-03]
 [9.87787260e-01 1.22127401e-02]
 [2.92348812e-02 9.70765119e-01]
 [2.16112070e-02 9.78388793e-01]
 [4.71067990e-03 9.95289320e-01]
 [9.97737965e-01 2.26203529e-03]
 [9.94271392e-01 5.72860828e-03]
 [9.55097505e-01 4.49024947e-02]
 [8.03063004e-02 9.19693700e-01]
 [1.82713588e-01 8.17286412e-01]
 [9.84540804e-01 1.54591958e-02]
 [1.76583074e-02 9.82341693e-01]
 [9.97889733e-01 2.11026718e-03]
 [1.25019555e-02 9.87498045e-01]
 [9.99557542e-01 4.42458023e-04]
 [9.91023482e-01 8.97651808e-03]
 [5.00692169e-03 9.94993078e-01]
 [1.97817665e-02 9.80218234e-01]
 [9.99755470e-01 2.44529840e-04]
 [9.82880360e-01 1.71196405e-02]
 [3.89098515e-02 9.61090149e-01]
 [9.84467295e-01 1.55327049e-02]
 [3.56714091e-03 9.96432859e-01]
 [9.98084082e-01 1.91591825e-03]
 [4.37375697e-04 9.99562624e-01]
 [9.36178200e-01 6.38218000e-02]
 [9.93211312e-01 6.78868836e-03]
 [1.25648672e-02 9.87435133e-01]
 [2.54768701e-02 9.74523130e-01]
 [4.49658904e-01 5.50341096e-01]
 [9.99681065e-01 3.18934903e-04]
 [5.03374468e-04 9.99496626e-01]
 [9.96701865e-01 3.29813527e-03]
 [7.57130093e-01 2.42869907e-01]
 [9.97348897e-01 2.65110268e-03]
 [5.05421626e-03 9.94945784e-01]
 [4.11103635e-03 9.95888964e-01]
 [9.94984749e-01 5.01525080e-03]
 [9.95450903e-01 4.54909723e-03]
 [5.03496834e-03 9.94965032e-01]
 [9.98841279e-01 1.15872115e-03]
 [2.78953412e-02 9.72104659e-01]
 [9.96475502e-01 3.52449842e-03]
 [7.40940988e-01 2.59059012e-01]
 [9.99580517e-01 4.19482997e-04]
 [2.08398735e-01 7.91601265e-01]
 [9.39566952e-01 6.04330484e-02]
 [9.84254502e-01 1.57454980e-02]
 [9.86002562e-01 1.39974381e-02]
 [7.28927049e-01 2.71072951e-01]
 [9.99816587e-01 1.83412660e-04]
 [9.98877904e-01 1.12209650e-03]
 [9.60243177e-01 3.97568233e-02]
 [9.99252313e-01 7.47687235e-04]
 [9.82099418e-01 1.79005821e-02]
 [9.99530181e-01 4.69818874e-04]
 [9.97289130e-01 2.71087045e-03]
 [9.94852516e-01 5.14748389e-03]
 [9.94473845e-01 5.52615498e-03]
 [9.96886105e-01 3.11389509e-03]
 [9.90082366e-01 9.91763443e-03]
 [9.97843431e-01 2.15656864e-03]
 [9.86939812e-01 1.30601879e-02]
 [9.93538273e-01 6.46172660e-03]
 [9.98459659e-01 1.54034084e-03]
 [9.97585296e-01 2.41470367e-03]
 [1.54942723e-01 8.45057277e-01]
 [9.98311799e-01 1.68820125e-03]
 [9.99375533e-01 6.24467386e-04]
 [1.05858389e-03 9.98941416e-01]
 [3.65715441e-03 9.96342846e-01]
 [3.01176027e-01 6.98823973e-01]
 [9.00073781e-02 9.09992622e-01]
 [9.97614812e-01 2.38518775e-03]
 [9.99196684e-01 8.03316202e-04]
 [1.71025653e-03 9.98289743e-01]
 [9.44912353e-01 5.50876465e-02]
 [7.99871827e-03 9.92001282e-01]
 [9.96667284e-01 3.33271615e-03]
 [8.91663653e-01 1.08336347e-01]
 [9.84676904e-01 1.53230965e-02]
 [9.88226907e-01 1.17730933e-02]
 [9.34975699e-01 6.50243014e-02]
 [9.41832828e-01 5.81671722e-02]
 [2.21271371e-03 9.97787286e-01]
 [7.49934477e-01 2.50065523e-01]
 [9.98641416e-01 1.35858361e-03]
 [9.19541367e-01 8.04586332e-02]
 [9.57529798e-04 9.99042470e-01]
 [9.96921958e-01 3.07804190e-03]
 [9.91684112e-01 8.31588776e-03]
 [9.94630375e-01 5.36962537e-03]
 [9.94156282e-01 5.84371810e-03]
 [9.96576034e-01 3.42396594e-03]
 [6.70404579e-05 9.99932960e-01]
 [4.48170324e-01 5.51829676e-01]
 [1.18383891e-02 9.88161611e-01]
 [9.88958761e-01 1.10412392e-02]
 [6.89866704e-02 9.31013330e-01]
 [1.88296063e-02 9.81170394e-01]
 [9.84443012e-01 1.55569877e-02]
 [9.60344655e-01 3.96553451e-02]
 [9.96558327e-01 3.44167330e-03]
 [9.99520819e-01 4.79181265e-04]
 [3.36500622e-02 9.66349938e-01]
 [9.97225096e-01 2.77490368e-03]
 [9.98543074e-01 1.45692608e-03]
 [3.64930117e-02 9.63506988e-01]
 [6.35800595e-03 9.93641994e-01]
 [1.53527307e-02 9.84647269e-01]
 [9.94982406e-01 5.01759389e-03]
 [9.72934053e-01 2.70659471e-02]
 [9.93591612e-01 6.40838827e-03]
 [9.81080897e-01 1.89191032e-02]
 [9.64237847e-01 3.57621527e-02]
 [9.98926800e-01 1.07319971e-03]
 [9.90333570e-01 9.66643049e-03]
 [1.16515433e-01 8.83484567e-01]
 [8.04214964e-01 1.95785036e-01]
 [9.90088093e-01 9.91190696e-03]
 [9.99807705e-01 1.92294646e-04]
 [9.88438707e-01 1.15612935e-02]
 [9.92694292e-01 7.30570806e-03]
 [2.71185144e-03 9.97288149e-01]
 [2.88051035e-04 9.99711949e-01]
 [9.99000150e-01 9.99850294e-04]
 [7.80069056e-01 2.19930944e-01]
 [9.75931880e-01 2.40681201e-02]
 [2.51718096e-01 7.48281904e-01]
 [3.89882829e-04 9.99610117e-01]
 [8.96834289e-01 1.03165711e-01]
 [9.97558357e-01 2.44164339e-03]
 [2.18232790e-02 9.78176721e-01]
 [9.96973461e-03 9.90030265e-01]
 [4.99806874e-01 5.00193126e-01]
 [9.85801911e-01 1.41980891e-02]
 [9.97185731e-01 2.81426885e-03]
 [7.02425274e-01 2.97574726e-01]
 [4.97335019e-05 9.99950266e-01]
 [9.77173923e-01 2.28260773e-02]
 [9.77165859e-01 2.28341411e-02]
 [9.11927071e-01 8.80729291e-02]
 [9.65414936e-01 3.45850642e-02]
 [9.97449802e-01 2.55019771e-03]
 [9.99350092e-01 6.49907712e-04]
 [9.98966878e-01 1.03312168e-03]
 [9.94667594e-01 5.33240560e-03]
 [8.81507784e-01 1.18492216e-01]
 [9.99299967e-01 7.00033187e-04]
 [9.90675055e-01 9.32494470e-03]
 [9.77229800e-01 2.27701998e-02]
 [6.77638134e-04 9.99322362e-01]
 [9.79676745e-01 2.03232549e-02]
 [1.34247433e-02 9.86575257e-01]
 [9.13934520e-01 8.60654796e-02]
 [9.14434838e-01 8.55651618e-02]
 [9.97428892e-01 2.57110758e-03]
 [9.29279337e-03 9.90707207e-01]
 [4.39364277e-01 5.60635723e-01]
 [2.89208099e-01 7.10791901e-01]
 [2.57420115e-01 7.42579885e-01]
 [6.19488960e-04 9.99380511e-01]
 [9.83467131e-01 1.65328693e-02]
 [9.99051246e-01 9.48753786e-04]
 [1.16332661e-01 8.83667339e-01]
 [6.91240590e-01 3.08759410e-01]
 [1.26366401e-01 8.73633599e-01]
 [2.93367829e-01 7.06632171e-01]
 [9.53521590e-03 9.90464784e-01]
 [1.06034783e-02 9.89396522e-01]
 [6.19270686e-01 3.80729314e-01]
 [9.82140045e-01 1.78599554e-02]
 [9.95988168e-01 4.01183246e-03]
 [9.83716251e-01 1.62837490e-02]
 [9.99444047e-01 5.55953254e-04]
 [8.56824968e-01 1.43175032e-01]
 [4.63347960e-02 9.53665204e-01]
 [7.43461530e-01 2.56538470e-01]
 [9.98348781e-01 1.65121939e-03]
 [9.63360646e-01 3.66393538e-02]
 [9.93867688e-01 6.13231151e-03]
 [9.96401825e-01 3.59817463e-03]
 [9.95915590e-01 4.08440999e-03]
 [9.82668390e-01 1.73316101e-02]
 [9.52807052e-01 4.71929479e-02]
 [9.43785078e-01 5.62149218e-02]
 [9.99110889e-01 8.89111168e-04]
 [9.04882010e-01 9.51179904e-02]
 [6.75059679e-01 3.24940321e-01]
 [9.94716302e-01 5.28369809e-03]
 [9.92594661e-01 7.40533930e-03]
 [9.93947123e-01 6.05287685e-03]
 [9.95180761e-01 4.81923871e-03]
 [2.45379928e-02 9.75462007e-01]
 [9.98385703e-01 1.61429727e-03]
 [9.96755247e-01 3.24475328e-03]
 [1.09679236e-04 9.99890321e-01]
 [9.73908673e-01 2.60913274e-02]
 [4.60800858e-02 9.53919914e-01]
 [9.98599466e-01 1.40053405e-03]
 [9.99883360e-01 1.16639625e-04]
 [1.27085611e-01 8.72914389e-01]
 [9.92230242e-01 7.76975805e-03]
 [9.99206075e-01 7.93925264e-04]
 [7.92828404e-01 2.07171596e-01]
 [9.83659621e-01 1.63403794e-02]
 [1.03071081e-01 8.96928919e-01]
 [9.95680618e-01 4.31938248e-03]
 [3.87350168e-01 6.12649832e-01]
 [1.58368154e-02 9.84163185e-01]
 [9.97338088e-01 2.66191175e-03]
 [9.79343090e-02 9.02065691e-01]
 [3.73267107e-01 6.26732893e-01]
 [2.14502491e-02 9.78549751e-01]
 [9.94000241e-01 5.99975876e-03]
 [9.98648287e-01 1.35171262e-03]
 [9.96656166e-01 3.34383373e-03]
 [9.98899494e-01 1.10050577e-03]
 [9.97860699e-01 2.13930120e-03]
 [3.17179696e-03 9.96828203e-01]
 [9.98159127e-01 1.84087308e-03]
 [9.83040707e-01 1.69592932e-02]
 [7.94747215e-01 2.05252785e-01]
 [9.03215946e-03 9.90967841e-01]
 [9.87699858e-01 1.23001421e-02]
 [9.93396801e-01 6.60319944e-03]
 [9.94192439e-01 5.80756079e-03]
 [5.66290670e-01 4.33709330e-01]
 [4.81763170e-01 5.18236830e-01]
 [8.68514728e-03 9.91314853e-01]
 [9.92971043e-01 7.02895660e-03]
 [5.03152208e-03 9.94968478e-01]
 [9.91893887e-01 8.10611350e-03]
 [9.98850826e-01 1.14917396e-03]
 [3.14310661e-01 6.85689339e-01]
 [9.98710601e-01 1.28939912e-03]
 [9.96838788e-01 3.16121179e-03]
 [9.89722562e-01 1.02774376e-02]
 [5.96110848e-01 4.03889152e-01]
 [1.03717228e-03 9.98962828e-01]
 [4.18230900e-01 5.81769100e-01]
 [9.82137782e-01 1.78622185e-02]
 [9.92843087e-01 7.15691320e-03]
 [1.84974165e-02 9.81502584e-01]
 [9.97863842e-01 2.13615818e-03]
 [2.29506639e-01 7.70493361e-01]
 [6.81794252e-03 9.93182057e-01]
 [9.98868422e-01 1.13157788e-03]
 [3.05773199e-05 9.99969423e-01]
 [9.99617530e-01 3.82470272e-04]
 [1.72156263e-03 9.98278437e-01]
 [9.99448863e-01 5.51136530e-04]
 [9.65785477e-01 3.42145227e-02]
 [1.77708022e-02 9.82229198e-01]
 [9.92352529e-01 7.64747131e-03]
 [8.20169506e-03 9.91798305e-01]
 [9.98126586e-01 1.87341384e-03]
 [1.24966523e-03 9.98750335e-01]
 [9.33633773e-01 6.63662267e-02]
 [9.96409794e-01 3.59020628e-03]
 [9.96207447e-01 3.79255285e-03]
 [9.81413734e-01 1.85862657e-02]
 [1.19045699e-01 8.80954301e-01]
 [4.58645173e-01 5.41354827e-01]
 [1.61621155e-02 9.83837885e-01]
 [7.25808775e-02 9.27419122e-01]
 [3.75705883e-02 9.62429412e-01]
 [8.94118488e-01 1.05881512e-01]
 [9.88220568e-01 1.17794320e-02]
 [3.67098957e-03 9.96329010e-01]
 [9.48744140e-01 5.12558599e-02]
 [9.98711859e-01 1.28814071e-03]
 [9.81593827e-01 1.84061734e-02]
 [9.25666788e-01 7.43332118e-02]
 [9.96498365e-01 3.50163506e-03]
 [9.96702628e-01 3.29737163e-03]
 [9.98214979e-01 1.78502148e-03]
 [9.13755088e-01 8.62449121e-02]
 [9.99697595e-01 3.02405226e-04]
 [8.84889943e-01 1.15110057e-01]
 [2.56026800e-03 9.97439732e-01]
 [9.92754801e-01 7.24519933e-03]
 [9.99478920e-01 5.21079926e-04]
 [9.97977417e-01 2.02258285e-03]
 [6.95669292e-01 3.04330708e-01]
 [4.22922571e-01 5.77077429e-01]
 [1.88380388e-01 8.11619612e-01]
 [7.77107158e-01 2.22892842e-01]
 [9.96332660e-01 3.66734028e-03]
 [9.72186352e-01 2.78136478e-02]
 [9.95368392e-01 4.63160848e-03]
 [9.96448377e-01 3.55162271e-03]
 [9.89266249e-01 1.07337510e-02]
 [9.16269540e-01 8.37304602e-02]
 [6.30052239e-04 9.99369948e-01]
 [9.91289172e-01 8.71082754e-03]
 [9.98599701e-01 1.40029852e-03]
 [4.14451844e-02 9.58554816e-01]
 [9.93528999e-01 6.47100056e-03]
 [9.96779626e-01 3.22037407e-03]
 [9.99563789e-01 4.36211011e-04]
 [2.86618946e-01 7.13381054e-01]
 [9.98816779e-01 1.18322149e-03]
 [9.99020876e-01 9.79123621e-04]
 [1.15130847e-01 8.84869153e-01]
 [9.89328552e-01 1.06714480e-02]
 [4.56694016e-01 5.43305984e-01]
 [1.62275791e-03 9.98377242e-01]
 [7.31550575e-02 9.26844943e-01]
 [9.82927088e-01 1.70729120e-02]
 [1.01187740e-02 9.89881226e-01]
 [2.37019626e-01 7.62980374e-01]
 [9.99454111e-01 5.45888725e-04]
 [2.59739717e-02 9.74026028e-01]
 [9.44683944e-04 9.99055316e-01]
 [8.84659647e-01 1.15340353e-01]
 [5.06757148e-03 9.94932429e-01]
 [9.59745968e-01 4.02540317e-02]
 [1.03158652e-02 9.89684135e-01]
 [9.89616110e-01 1.03838903e-02]
 [9.61947583e-01 3.80524173e-02]
 [9.99650330e-01 3.49670390e-04]
 [9.94048188e-01 5.95181171e-03]
 [9.94235282e-01 5.76471751e-03]
 [9.67593666e-01 3.24063341e-02]
 [8.85926020e-01 1.14073980e-01]
 [9.78965769e-01 2.10342315e-02]
 [8.78271688e-01 1.21728312e-01]
 [9.98599331e-01 1.40066901e-03]
 [9.87841390e-01 1.21586102e-02]
 [8.92558278e-02 9.10744172e-01]
 [9.99610164e-01 3.89836093e-04]
 [7.19337072e-04 9.99280663e-01]
 [9.85892127e-01 1.41078732e-02]
 [9.97279957e-01 2.72004337e-03]
 [3.07265235e-03 9.96927348e-01]
 [9.91313707e-01 8.68629341e-03]
 [9.99100521e-01 8.99478512e-04]
 [6.65070413e-02 9.33492959e-01]
 [6.97453321e-01 3.02546679e-01]
 [6.86420340e-02 9.31357966e-01]
 [1.37806982e-02 9.86219302e-01]
 [3.00211545e-02 9.69978845e-01]
 [9.66621467e-01 3.33785331e-02]
 [9.99781236e-01 2.18764411e-04]
 [1.19701875e-01 8.80298125e-01]
 [9.94527442e-01 5.47255785e-03]
 [9.97956893e-01 2.04310669e-03]
 [9.87795955e-01 1.22040452e-02]
 [1.27174167e-01 8.72825833e-01]
 [9.98835399e-01 1.16460122e-03]
 [9.62090240e-01 3.79097600e-02]
 [1.48420488e-01 8.51579512e-01]
 [9.93042042e-01 6.95795778e-03]
 [9.97675754e-01 2.32424611e-03]
 [2.07016093e-02 9.79298391e-01]
 [9.97045522e-01 2.95447780e-03]
 [7.40685686e-01 2.59314314e-01]
 [9.97212948e-01 2.78705202e-03]
 [9.93496780e-01 6.50322047e-03]
 [6.49502566e-03 9.93504974e-01]
 [9.82813201e-01 1.71867991e-02]
 [9.97555803e-01 2.44419675e-03]
 [1.49262739e-04 9.99850737e-01]
 [8.02405450e-02 9.19759455e-01]
 [9.95436505e-01 4.56349465e-03]
 [6.52228845e-01 3.47771155e-01]
 [9.11886156e-01 8.81138442e-02]
 [1.50333645e-02 9.84966635e-01]
 [9.99654158e-01 3.45841922e-04]
 [2.75134109e-01 7.24865891e-01]
 [9.97852839e-05 9.99900215e-01]
 [5.35777709e-01 4.64222291e-01]
 [9.98620363e-01 1.37963664e-03]
 [9.94115524e-01 5.88447573e-03]
 [1.51516301e-03 9.98484837e-01]
 [9.99903913e-01 9.60867931e-05]
 [9.92934282e-01 7.06571761e-03]]
[0.58552821 0.41447179]
[9.93824235e-01 4.14471786e-01 6.49964553e-03 2.16138250e-02
 3.61982520e-03 5.76306219e-01 1.09144439e-03 4.57920111e-03
 1.57716949e-02 7.88881402e-04 3.78641846e-02 6.72812831e-03
 8.98964270e-03 9.34747876e-01 7.93882950e-03 9.98896804e-01
 9.68722911e-01 2.16355125e-02 8.97026475e-01 9.96711672e-01
 7.34410320e-01 3.34176012e-03 6.49428066e-04 1.64168761e-03
 3.51789059e-03 3.04996739e-03 5.25962809e-03 9.99714053e-01
 3.90862253e-03 2.17908447e-03 1.25531899e-04 9.94376021e-01
 2.51715454e-01 1.12333669e-02 9.99917035e-01 9.98021266e-01
 8.08100048e-01 2.94872702e-03 1.22127401e-02 9.70765119e-01
 9.78388793e-01 9.95289320e-01 2.26203529e-03 5.72860828e-03
 4.49024947e-02 9.19693700e-01 8.17286412e-01 1.54591958e-02
 9.82341693e-01 2.11026718e-03 9.87498045e-01 4.42458023e-04
 8.97651808e-03 9.94993078e-01 9.80218234e-01 2.44529840e-04
 1.71196405e-02 9.61090149e-01 1.55327049e-02 9.96432859e-01
 1.91591825e-03 9.99562624e-01 6.38218000e-02 6.78868836e-03
 9.87435133e-01 9.74523130e-01 5.50341096e-01 3.18934903e-04
 9.99496626e-01 3.29813527e-03 2.42869907e-01 2.65110268e-03
 9.94945784e-01 9.95888964e-01 5.01525080e-03 4.54909723e-03
 9.94965032e-01 1.15872115e-03 9.72104659e-01 3.52449842e-03
 2.59059012e-01 4.19482997e-04 7.91601265e-01 6.04330484e-02
 1.57454980e-02 1.39974381e-02 2.71072951e-01 1.83412660e-04
 1.12209650e-03 3.97568233e-02 7.47687235e-04 1.79005821e-02
 4.69818874e-04 2.71087045e-03 5.14748389e-03 5.52615498e-03
 3.11389509e-03 9.91763443e-03 2.15656864e-03 1.30601879e-02
 6.46172660e-03 1.54034084e-03 2.41470367e-03 8.45057277e-01
 1.68820125e-03 6.24467386e-04 9.98941416e-01 9.96342846e-01
 6.98823973e-01 9.09992622e-01 2.38518775e-03 8.03316202e-04
 9.98289743e-01 5.50876465e-02 9.92001282e-01 3.33271615e-03
 1.08336347e-01 1.53230965e-02 1.17730933e-02 6.50243014e-02
 5.81671722e-02 9.97787286e-01 2.50065523e-01 1.35858361e-03
 8.04586332e-02 9.99042470e-01 3.07804190e-03 8.31588776e-03
 5.36962537e-03 5.84371810e-03 3.42396594e-03 9.99932960e-01
 5.51829676e-01 9.88161611e-01 1.10412392e-02 9.31013330e-01
 9.81170394e-01 1.55569877e-02 3.96553451e-02 3.44167330e-03
 4.79181265e-04 9.66349938e-01 2.77490368e-03 1.45692608e-03
 9.63506988e-01 9.93641994e-01 9.84647269e-01 5.01759389e-03
 2.70659471e-02 6.40838827e-03 1.89191032e-02 3.57621527e-02
 1.07319971e-03 9.66643049e-03 8.83484567e-01 1.95785036e-01
 9.91190696e-03 1.92294646e-04 1.15612935e-02 7.30570806e-03
 9.97288149e-01 9.99711949e-01 9.99850294e-04 2.19930944e-01
 2.40681201e-02 7.48281904e-01 9.99610117e-01 1.03165711e-01
 2.44164339e-03 9.78176721e-01 9.90030265e-01 5.00193126e-01
 1.41980891e-02 2.81426885e-03 2.97574726e-01 9.99950266e-01
 2.28260773e-02 2.28341411e-02 8.80729291e-02 3.45850642e-02
 2.55019771e-03 6.49907712e-04 1.03312168e-03 5.33240560e-03
 1.18492216e-01 7.00033187e-04 9.32494470e-03 2.27701998e-02
 9.99322362e-01 2.03232549e-02 9.86575257e-01 8.60654796e-02
 8.55651618e-02 2.57110758e-03 9.90707207e-01 5.60635723e-01
 7.10791901e-01 7.42579885e-01 9.99380511e-01 1.65328693e-02
 9.48753786e-04 8.83667339e-01 3.08759410e-01 8.73633599e-01
 7.06632171e-01 9.90464784e-01 9.89396522e-01 3.80729314e-01
 1.78599554e-02 4.01183246e-03 1.62837490e-02 5.55953254e-04
 1.43175032e-01 9.53665204e-01 2.56538470e-01 1.65121939e-03
 3.66393538e-02 6.13231151e-03 3.59817463e-03 4.08440999e-03
 1.73316101e-02 4.71929479e-02 5.62149218e-02 8.89111168e-04
 9.51179904e-02 3.24940321e-01 5.28369809e-03 7.40533930e-03
 6.05287685e-03 4.81923871e-03 9.75462007e-01 1.61429727e-03
 3.24475328e-03 9.99890321e-01 2.60913274e-02 9.53919914e-01
 1.40053405e-03 1.16639625e-04 8.72914389e-01 7.76975805e-03
 7.93925264e-04 2.07171596e-01 1.63403794e-02 8.96928919e-01
 4.31938248e-03 6.12649832e-01 9.84163185e-01 2.66191175e-03
 9.02065691e-01 6.26732893e-01 9.78549751e-01 5.99975876e-03
 1.35171262e-03 3.34383373e-03 1.10050577e-03 2.13930120e-03
 9.96828203e-01 1.84087308e-03 1.69592932e-02 2.05252785e-01
 9.90967841e-01 1.23001421e-02 6.60319944e-03 5.80756079e-03
 4.33709330e-01 5.18236830e-01 9.91314853e-01 7.02895660e-03
 9.94968478e-01 8.10611350e-03 1.14917396e-03 6.85689339e-01
 1.28939912e-03 3.16121179e-03 1.02774376e-02 4.03889152e-01
 9.98962828e-01 5.81769100e-01 1.78622185e-02 7.15691320e-03
 9.81502584e-01 2.13615818e-03 7.70493361e-01 9.93182057e-01
 1.13157788e-03 9.99969423e-01 3.82470272e-04 9.98278437e-01
 5.51136530e-04 3.42145227e-02 9.82229198e-01 7.64747131e-03
 9.91798305e-01 1.87341384e-03 9.98750335e-01 6.63662267e-02
 3.59020628e-03 3.79255285e-03 1.85862657e-02 8.80954301e-01
 5.41354827e-01 9.83837885e-01 9.27419122e-01 9.62429412e-01
 1.05881512e-01 1.17794320e-02 9.96329010e-01 5.12558599e-02
 1.28814071e-03 1.84061734e-02 7.43332118e-02 3.50163506e-03
 3.29737163e-03 1.78502148e-03 8.62449121e-02 3.02405226e-04
 1.15110057e-01 9.97439732e-01 7.24519933e-03 5.21079926e-04
 2.02258285e-03 3.04330708e-01 5.77077429e-01 8.11619612e-01
 2.22892842e-01 3.66734028e-03 2.78136478e-02 4.63160848e-03
 3.55162271e-03 1.07337510e-02 8.37304602e-02 9.99369948e-01
 8.71082754e-03 1.40029852e-03 9.58554816e-01 6.47100056e-03
 3.22037407e-03 4.36211011e-04 7.13381054e-01 1.18322149e-03
 9.79123621e-04 8.84869153e-01 1.06714480e-02 5.43305984e-01
 9.98377242e-01 9.26844943e-01 1.70729120e-02 9.89881226e-01
 7.62980374e-01 5.45888725e-04 9.74026028e-01 9.99055316e-01
 1.15340353e-01 9.94932429e-01 4.02540317e-02 9.89684135e-01
 1.03838903e-02 3.80524173e-02 3.49670390e-04 5.95181171e-03
 5.76471751e-03 3.24063341e-02 1.14073980e-01 2.10342315e-02
 1.21728312e-01 1.40066901e-03 1.21586102e-02 9.10744172e-01
 3.89836093e-04 9.99280663e-01 1.41078732e-02 2.72004337e-03
 9.96927348e-01 8.68629341e-03 8.99478512e-04 9.33492959e-01
 3.02546679e-01 9.31357966e-01 9.86219302e-01 9.69978845e-01
 3.33785331e-02 2.18764411e-04 8.80298125e-01 5.47255785e-03
 2.04310669e-03 1.22040452e-02 8.72825833e-01 1.16460122e-03
 3.79097600e-02 8.51579512e-01 6.95795778e-03 2.32424611e-03
 9.79298391e-01 2.95447780e-03 2.59314314e-01 2.78705202e-03
 6.50322047e-03 9.93504974e-01 1.71867991e-02 2.44419675e-03
 9.99850737e-01 9.19759455e-01 4.56349465e-03 3.47771155e-01
 8.81138442e-02 9.84966635e-01 3.45841922e-04 7.24865891e-01
 9.99900215e-01 4.64222291e-01 1.37963664e-03 5.88447573e-03
 9.98484837e-01 9.60867931e-05 7.06571761e-03]
[9.93824235e-01 4.14471786e-01 6.49964553e-03 2.16138250e-02
 3.61982520e-03 5.76306219e-01 1.09144439e-03 4.57920111e-03
 1.57716949e-02 7.88881402e-04 3.78641846e-02 6.72812831e-03
 8.98964270e-03 9.34747876e-01 7.93882950e-03 9.98896804e-01
 9.68722911e-01 2.16355125e-02 8.97026475e-01 9.96711672e-01
 7.34410320e-01 3.34176012e-03 6.49428066e-04 1.64168761e-03
 3.51789059e-03 3.04996739e-03 5.25962809e-03 9.99714053e-01
 3.90862253e-03 2.17908447e-03 1.25531899e-04 9.94376021e-01
 2.51715454e-01 1.12333669e-02 9.99917035e-01 9.98021266e-01
 8.08100048e-01 2.94872702e-03 1.22127401e-02 9.70765119e-01
 9.78388793e-01 9.95289320e-01 2.26203529e-03 5.72860828e-03
 4.49024947e-02 9.19693700e-01 8.17286412e-01 1.54591958e-02
 9.82341693e-01 2.11026718e-03 9.87498045e-01 4.42458023e-04
 8.97651808e-03 9.94993078e-01 9.80218234e-01 2.44529840e-04
 1.71196405e-02 9.61090149e-01 1.55327049e-02 9.96432859e-01
 1.91591825e-03 9.99562624e-01 6.38218000e-02 6.78868836e-03
 9.87435133e-01 9.74523130e-01 5.50341096e-01 3.18934903e-04
 9.99496626e-01 3.29813527e-03 2.42869907e-01 2.65110268e-03
 9.94945784e-01 9.95888964e-01 5.01525080e-03 4.54909723e-03
 9.94965032e-01 1.15872115e-03 9.72104659e-01 3.52449842e-03
 2.59059012e-01 4.19482997e-04 7.91601265e-01 6.04330484e-02
 1.57454980e-02 1.39974381e-02 2.71072951e-01 1.83412660e-04
 1.12209650e-03 3.97568233e-02 7.47687235e-04 1.79005821e-02
 4.69818874e-04 2.71087045e-03 5.14748389e-03 5.52615498e-03
 3.11389509e-03 9.91763443e-03 2.15656864e-03 1.30601879e-02
 6.46172660e-03 1.54034084e-03 2.41470367e-03 8.45057277e-01
 1.68820125e-03 6.24467386e-04 9.98941416e-01 9.96342846e-01
 6.98823973e-01 9.09992622e-01 2.38518775e-03 8.03316202e-04
 9.98289743e-01 5.50876465e-02 9.92001282e-01 3.33271615e-03
 1.08336347e-01 1.53230965e-02 1.17730933e-02 6.50243014e-02
 5.81671722e-02 9.97787286e-01 2.50065523e-01 1.35858361e-03
 8.04586332e-02 9.99042470e-01 3.07804190e-03 8.31588776e-03
 5.36962537e-03 5.84371810e-03 3.42396594e-03 9.99932960e-01
 5.51829676e-01 9.88161611e-01 1.10412392e-02 9.31013330e-01
 9.81170394e-01 1.55569877e-02 3.96553451e-02 3.44167330e-03
 4.79181265e-04 9.66349938e-01 2.77490368e-03 1.45692608e-03
 9.63506988e-01 9.93641994e-01 9.84647269e-01 5.01759389e-03
 2.70659471e-02 6.40838827e-03 1.89191032e-02 3.57621527e-02
 1.07319971e-03 9.66643049e-03 8.83484567e-01 1.95785036e-01
 9.91190696e-03 1.92294646e-04 1.15612935e-02 7.30570806e-03
 9.97288149e-01 9.99711949e-01 9.99850294e-04 2.19930944e-01
 2.40681201e-02 7.48281904e-01 9.99610117e-01 1.03165711e-01
 2.44164339e-03 9.78176721e-01 9.90030265e-01 5.00193126e-01
 1.41980891e-02 2.81426885e-03 2.97574726e-01 9.99950266e-01
 2.28260773e-02 2.28341411e-02 8.80729291e-02 3.45850642e-02
 2.55019771e-03 6.49907712e-04 1.03312168e-03 5.33240560e-03
 1.18492216e-01 7.00033187e-04 9.32494470e-03 2.27701998e-02
 9.99322362e-01 2.03232549e-02 9.86575257e-01 8.60654796e-02
 8.55651618e-02 2.57110758e-03 9.90707207e-01 5.60635723e-01
 7.10791901e-01 7.42579885e-01 9.99380511e-01 1.65328693e-02
 9.48753786e-04 8.83667339e-01 3.08759410e-01 8.73633599e-01
 7.06632171e-01 9.90464784e-01 9.89396522e-01 3.80729314e-01
 1.78599554e-02 4.01183246e-03 1.62837490e-02 5.55953254e-04
 1.43175032e-01 9.53665204e-01 2.56538470e-01 1.65121939e-03
 3.66393538e-02 6.13231151e-03 3.59817463e-03 4.08440999e-03
 1.73316101e-02 4.71929479e-02 5.62149218e-02 8.89111168e-04
 9.51179904e-02 3.24940321e-01 5.28369809e-03 7.40533930e-03
 6.05287685e-03 4.81923871e-03 9.75462007e-01 1.61429727e-03
 3.24475328e-03 9.99890321e-01 2.60913274e-02 9.53919914e-01
 1.40053405e-03 1.16639625e-04 8.72914389e-01 7.76975805e-03
 7.93925264e-04 2.07171596e-01 1.63403794e-02 8.96928919e-01
 4.31938248e-03 6.12649832e-01 9.84163185e-01 2.66191175e-03
 9.02065691e-01 6.26732893e-01 9.78549751e-01 5.99975876e-03
 1.35171262e-03 3.34383373e-03 1.10050577e-03 2.13930120e-03
 9.96828203e-01 1.84087308e-03 1.69592932e-02 2.05252785e-01
 9.90967841e-01 1.23001421e-02 6.60319944e-03 5.80756079e-03
 4.33709330e-01 5.18236830e-01 9.91314853e-01 7.02895660e-03
 9.94968478e-01 8.10611350e-03 1.14917396e-03 6.85689339e-01
 1.28939912e-03 3.16121179e-03 1.02774376e-02 4.03889152e-01
 9.98962828e-01 5.81769100e-01 1.78622185e-02 7.15691320e-03
 9.81502584e-01 2.13615818e-03 7.70493361e-01 9.93182057e-01
 1.13157788e-03 9.99969423e-01 3.82470272e-04 9.98278437e-01
 5.51136530e-04 3.42145227e-02 9.82229198e-01 7.64747131e-03
 9.91798305e-01 1.87341384e-03 9.98750335e-01 6.63662267e-02
 3.59020628e-03 3.79255285e-03 1.85862657e-02 8.80954301e-01
 5.41354827e-01 9.83837885e-01 9.27419122e-01 9.62429412e-01
 1.05881512e-01 1.17794320e-02 9.96329010e-01 5.12558599e-02
 1.28814071e-03 1.84061734e-02 7.43332118e-02 3.50163506e-03
 3.29737163e-03 1.78502148e-03 8.62449121e-02 3.02405226e-04
 1.15110057e-01 9.97439732e-01 7.24519933e-03 5.21079926e-04
 2.02258285e-03 3.04330708e-01 5.77077429e-01 8.11619612e-01
 2.22892842e-01 3.66734028e-03 2.78136478e-02 4.63160848e-03
 3.55162271e-03 1.07337510e-02 8.37304602e-02 9.99369948e-01
 8.71082754e-03 1.40029852e-03 9.58554816e-01 6.47100056e-03
 3.22037407e-03 4.36211011e-04 7.13381054e-01 1.18322149e-03
 9.79123621e-04 8.84869153e-01 1.06714480e-02 5.43305984e-01
 9.98377242e-01 9.26844943e-01 1.70729120e-02 9.89881226e-01
 7.62980374e-01 5.45888725e-04 9.74026028e-01 9.99055316e-01
 1.15340353e-01 9.94932429e-01 4.02540317e-02 9.89684135e-01
 1.03838903e-02 3.80524173e-02 3.49670390e-04 5.95181171e-03
 5.76471751e-03 3.24063341e-02 1.14073980e-01 2.10342315e-02
 1.21728312e-01 1.40066901e-03 1.21586102e-02 9.10744172e-01
 3.89836093e-04 9.99280663e-01 1.41078732e-02 2.72004337e-03
 9.96927348e-01 8.68629341e-03 8.99478512e-04 9.33492959e-01
 3.02546679e-01 9.31357966e-01 9.86219302e-01 9.69978845e-01
 3.33785331e-02 2.18764411e-04 8.80298125e-01 5.47255785e-03
 2.04310669e-03 1.22040452e-02 8.72825833e-01 1.16460122e-03
 3.79097600e-02 8.51579512e-01 6.95795778e-03 2.32424611e-03
 9.79298391e-01 2.95447780e-03 2.59314314e-01 2.78705202e-03
 6.50322047e-03 9.93504974e-01 1.71867991e-02 2.44419675e-03
 9.99850737e-01 9.19759455e-01 4.56349465e-03 3.47771155e-01
 8.81138442e-02 9.84966635e-01 3.45841922e-04 7.24865891e-01
 9.99900215e-01 4.64222291e-01 1.37963664e-03 5.88447573e-03
 9.98484837e-01 9.60867931e-05 7.06571761e-03]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
The Neural Network F1 Score is: 0.8611111111111112
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
The Neural Network F1 Score is: 0.8611111111111112
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
The Neural Network F1 Score is: 0.8611111111111112
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
The Neural Network F1 Score is: 0.8611111111111112
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network Confusion Matrix is:
The Neural Network F1 Score is: 0.8611111111111112
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network F1 Score is: 0.8611111111111112
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network F1 Score is: 0.8611111111111112
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network F1 Score is: 0.8611111111111112
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network F1 Score is: 0.8611111111111112
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network F1 Score is: 0.8611111111111112
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network F1 Score is: 0.8611111111111112
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
The Neural Network accuracy is 90.36144578313254
The Neural Network ROC AUC Scores are: 0.8889563721024394
The Neural Network's Weighted Average ROC AUC Score is: 0.8889563721024394
The Neural Network's Logarithmic Loss Score is: 3.4740870736498457
The Neural Network F1 Score is: 0.8611111111111112
The Neural Network Confusion Matrix is:
[[251  16]
 [ 24 124]]
check1
Index(['Signif_Avg', 'Pivot_Energy', 'Flux1000', 'Energy_Flux100',
       'PL_Flux_Density', 'PL_Index', 'LP_Flux_Density', 'LP_Index', 'LP_beta',
       'LP_SigCurv', 'LP_EPeak', 'PLEC_Flux_Density', 'PLEC_IndexS',
       'PLEC_ExpfactorS', 'PLEC_Exp_Index', 'PLEC_SigCurv', 'Npred',
       'Variability_Index', 'Frac_Variability', 'ASSOC_PROB_BAY',
       'Flux_Band_0', 'Flux_Band_1', 'Flux_Band_2', 'Flux_Band_3',
       'Flux_Band_4', 'Flux_Band_5', 'Flux_Band_6', 'Flux_Band_7',
       'nuFnu_Band_0', 'nuFnu_Band_1', 'nuFnu_Band_2', 'nuFnu_Band_3',
       'nuFnu_Band_4', 'nuFnu_Band_5', 'nuFnu_Band_6', 'nuFnu_Band_7',
       'Sqrt_TS_Band_2', 'Sqrt_TS_Band_3', 'Sqrt_TS_Band_4', 'Sqrt_TS_Band_5',
       'Flux_History_0', 'Flux_History_1', 'Flux_History_2', 'Flux_History_3',
       'Flux_History_4', 'Flux_History_5', 'Flux_History_6', 'Flux_History_7',
       'Sqrt_TS_History_0', 'Sqrt_TS_History_1', 'Sqrt_TS_History_2',
       'Sqrt_TS_History_3', 'Sqrt_TS_History_4', 'Sqrt_TS_History_5',
       'Sqrt_TS_History_6', 'Sqrt_TS_History_7', 'CLASS1'],
      dtype='object')
check1
